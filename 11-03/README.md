
# Домашнее задание к занятию «Микросервисы: подходы»
Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры. Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.

## Задача 1: Обеспечить разработку
Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Для хранения исходного кода с возможностью версионирования можно использовать GitHub или GitLab.
У них много общего:
* Запрос изменение (pull request)
* Сторонние интеграции 
* Вилка (fork) / клонирование репозитория 
* Ревью кода 
* Фрагменты кода 
* Отслеживание проблем 
* Расширенное управление разрешениями 
* Поддержка Markdown

Будем использовать GitLab, так как он дешевле и у него открытый исходный код, что возможно сыграет роль в будущем.

Так как мы используем GitLab, то для CI/CD будет использовать GitLab CI, встроенный в него. Это один из лучших CI/CD-инструментов, поскольку он предлагает различные функции, такие как просмотр кода, CI/CD, непрерывное развертывание и многое другое в рамках единой информационной панели.

Для использования GitLab CI/CD необходимо разместить кодовую базу в репозитории Git и указать сценарии для выполнения сборки, тестирования и развертывания в файле YAML с именем .gitlab-ci.yml, который должен присутствовать в корневом каталоге. Сценарии сгруппированы в задания и называются конвейером. Инструмент GitLab runner обнаруживает скрипты и запускает их.

Основные особенности GitLab CI

* GitLab CI предлагает API для более глубокой интеграции с инструментами сторонних разработчиков.

* Доступен для популярных платформ, таких как Windows, Linux и macOS.

* Веб-приложение GitLab CI отличается удобным интерфейсом.

* Параллельная сборка GitLab CI позволяет минимизировать время сборки, разделив одну сборку на несколько машин.

* Механизм кэширования в GitLab CI экономит время при выполнении задач. Вы можете совместно использовать кэш в одной и той же ветви и в разных ветвях, а также отключить кэш для определенных задач. Большое количество опций GitLab CI позволяет использовать механизм кэширования по мере необходимости.

* Задачи в GitLab CI могут выполняться последовательно и параллельно. Есть возможность создать собственный конвейер.

* Переход на GitLab CI с таких инструментов как Jenkins или CircleCI несложен.

* GitLab CI прост в использовании, поскольку сборки можно запускать через GitLab CI shell executor (как любую программу для терминала).



## Задача 2: Логи

Будем использовать ELK, как самый популярный вариант.
Плюсы ELK:
* Масштабируемость – кластер Elasticsearch (ES) расширяется «на лету» добавлением новых серверов. При этом распределение нагрузки по узлам происходит автоматически.
* Отказоустойчивость — в случае сбоя кластерных узлов данные не потеряются, а будут перераспределены, и поисковая система сама продолжит работу. Операционная стабильность достигается ведением логов на каждое изменение данных в хранилище сразу на нескольких узлах кластера.
* Гибкость поисковых фильтров, включая нечеткий поиск, возможности работы с восточными языками (китайский, японский, корейский) и мультиарендность, когда в рамках одного объекта ES можно динамически организовать несколько различных поисковых систем. Благодаря наличию встроенных анализаторов текста Elasticsearch автоматически выполняет токенизацию, лемматизацию, стемминг и прочие преобразования текста для решения NLP-задач, связанных с поиском данных.
* Управляемость ES по HTTP с помощью JSON-запросов за счет REST API и визуального веб-интерфейса Kibana.
* Универсальность – Logsatsh в потоковом режиме работает одновременно со множеством разных источников данных (СУБД, файлы, системные логи, веб-приложения и пр.), фильтруя и преобразуя их для отправки в хранилище ES. А NoSQL-природа Elasticsearch (отсутствие схемы) позволяет загружать в него JSON-объекты, которые автоматически индексируются и добавляются в базу поиска. Это позволяет ускорить прототипирование поисковых Big Data решений.

## Задача 3: Мониторинг

Можно использовать связку Prometheus + Grafana для сбора данных и их графического вывода.
Для получения метрик с удаленных узлов используется метод pull (сервер сам забирает данные). На узлы для сбора информации устанавливаются экспортеры (exporter) — пакеты, получающие данные для операционной системы или конкретного сервиса. Существует большое количество уже написанных экспортеров для различных приложений. Также метрики могут собираться с помощью механизма push — для этого используется компонент pushgateway, который должен быть установлен дополнительно.